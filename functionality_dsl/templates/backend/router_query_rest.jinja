# ========================================================================
# AUTO-GENERATED QUERY ROUTER
# ========================================================================

import json
import logging
from typing import Any, Dict, List

from fastapi import APIRouter, HTTPException

from app.core.http import get_http_client
from app.core.runtime.safe_eval import compile_safe, safe_globals
from app.core.utils import resolve_headers, interpolate_url, normalize_path_value


logger = logging.getLogger("fdsl.router.{{ endpoint.name }}")

router = APIRouter(
    prefix="{{ route_prefix }}",
    tags=["{{ endpoint.summary or endpoint.name }}"]
)

# ============================================================================
#                          CONFIGURATION
# ============================================================================

_EXTERNAL_REST_SOURCES = [
{%- for source in rest_inputs %}
    {
        "entity": "{{ source.entity }}",
        "alias": "{{ source.alias }}",
        "url": "{{ source.url }}",
        "headers": {{ source.headers }},
        "method": "{{ source.method }}",
        "attrs": [
        {%- for attr in source.attrs %}
            {"name": "{{ attr.name }}", "expr": {{ attr.pyexpr | tojson }}},
        {%- endfor %}
        ]
    },
{%- endfor %}
]

_INTERNAL_DEPENDENCIES = [
{%- for dep in computed_parents | default([], true) %}
    {"name": "{{ dep.name }}", "endpoint": "{{ dep.endpoint }}/"},
{%- endfor %}
]

_INLINE_COMPUTED_CHAIN = [
{%- for step in inline_chain or [] %}
    {
        "name": "{{ step.name }}",
        "attrs": [
        {%- for attr in step.attrs %}
            {"name": "{{ attr.name }}", "expr": {{ attr.pyexpr | tojson }}},
        {%- endfor %}
        ]{% if step.validations %},
        "validations": [
        {%- for v in step.validations %}
            {"pyexpr": {{ v.pyexpr | tojson }}},
        {%- endfor %}
        ]{% endif %}
    },

{%- endfor %}
]

_ENTITY_ATTRIBUTES = {
{%- for attr in computed_attrs %}
    "{{ attr.name }}": compile_safe({{ attr.pyexpr | tojson }}),
{%- endfor %}
}

{% set pparams = endpoint.path_params or [] %}
@router.get("", response_model=Dict[str, Any])
async def query_{{ endpoint.name | lower }}({% for p in pparams %}{{ p }}: str{% if not loop.last %}, {% endif %}{% endfor %}):
    """
    Query endpoint for {{ entity.name }}.
    Aggregates data from external sources and internal dependencies,
    then computes the final entity attributes.
    """
    http_client = get_http_client()
    context: Dict[str, Any] = {}

    # ----------------------------------------------------------------
    # STEP 0: Seed context with path parameters (if any)
    # ----------------------------------------------------------------
    {% if pparams|length %}
    context["{{ endpoint.name }}"] = {}
    for _param_name, _param_value in [
      {% for p in pparams %}("{{ p }}", {{ p }}){% if not loop.last %}, {% endif %}{% endfor %}
    ]:
        context["{{ endpoint.name }}"][_param_name] = normalize_path_value(_param_value)
    logger.debug(f"[CONTEXT] - Seeded path parameters: {list(context['{{ endpoint.name }}'].keys())}")
    {% endif %}

    try:
        # ----------------------------------------------------------------
        # STEP 1: Fetch external REST sources
        # ----------------------------------------------------------------
        for source_config in _EXTERNAL_REST_SOURCES:
            entity_name = source_config["entity"]
            source_alias = source_config["alias"]
            url = source_config["url"]
            url = interpolate_url(url, context)
            method = source_config["method"]
            
            logger.info(f"[FETCH] - Fetching {entity_name} from {url} ({method})")
            
            try:
                # Prepare headers
                headers = resolve_headers(source_config.get("headers", []))

                # Inject API key query params if necessary
                for key, value in source_config.get("headers", []):
                    if key == "__queryparam__":
                        separator = "&" if "?" in url else "?"
                        url = f"{url}{separator}{value}"
                
                # Make request
                response = await http_client.request(method, url, headers=headers)
                
                if response.status_code >= 400:
                    logger.error(f"[FETCH] - Failed to fetch {entity_name}: HTTP {response.status_code}")
                    raise HTTPException(
                        status_code=502,
                        detail=f"External source {entity_name} returned {response.status_code}"
                    )
                
                raw_payload = response.json()
                logger.debug(f"[FETCH] - {entity_name} payload type: {type(raw_payload)}")
                
                # Shape the data by evaluating attribute expressions
                shaped_data: Dict[str, Any] = {}
                evaluation_ctx = {source_alias: raw_payload}
                
                for attr_config in source_config.get("attrs", []):
                    attr_name = attr_config["name"]
                    attr_expr = attr_config["expr"]
                    
                    try:
                        compiled_expr = compile_safe(attr_expr)
                        shaped_data[attr_name] = eval(compiled_expr, safe_globals, evaluation_ctx)
                        logger.debug(f"[SHAPE] - {entity_name}.{attr_name} computed successfully")
                    except HTTPException:
                        raise 
                    except Exception as eval_error:
                        logger.error(f"[SHAPE] - Error computing {entity_name}.{attr_name}: {eval_error}", exc_info=True)
                        raise HTTPException(
                            status_code=500,
                            detail=f"Failed to compute {entity_name}.{attr_name}"
                        )
                
                # Default to raw payload if no attributes specified
                if not shaped_data:
                    shaped_data = {"raw": raw_payload}
                
                # Store in context under entity name
                context[entity_name] = shaped_data
                logger.info(f"[CONTEXT] - Stored {entity_name} with keys: {list(shaped_data.keys())}")
                
            except HTTPException:
                raise
            except Exception as fetch_error:
                logger.error(f"[FETCH] - Unexpected error fetching {entity_name}: {fetch_error}", exc_info=True)
                raise HTTPException(
                    status_code=502,
                    detail=f"Failed to fetch external source: {entity_name}"
                )

        # ----------------------------------------------------------------
        # STEP 2: Fetch internal computed dependencies
        # ----------------------------------------------------------------
        for dependency in _INTERNAL_DEPENDENCIES:
            entity_name = dependency["name"]
            endpoint_path = dependency["endpoint"]

            logger.info(f"[DEPENDENCY] - Fetching computed parent {entity_name} from {endpoint_path}")

            try:
                response = await http_client.get(f"http://{{ server.host }}:{{ server.port }}{endpoint_path}")

                if response.status_code >= 400:
                    logger.error(f"[DEPENDENCY] - Failed to fetch {entity_name}: HTTP {response.status_code}")
                    raise HTTPException(
                        status_code=502,
                        detail=f"Internal dependency {entity_name} returned {response.status_code}"
                    )

                payload = response.json()

                # Unwrap single-key envelope { "<EntityName>": <data> } if present
                if isinstance(payload, dict) and entity_name in payload and len(payload) == 1:
                    context[entity_name] = payload[entity_name]
                    logger.debug(
                        f"[DEPENDENCY] - Unwrapped envelope for {entity_name}; "
                        f"type={type(payload[entity_name]).__name__}"
                    )
                else:
                    # Store as-is (dict, list, scalar).
                    context[entity_name] = payload
                    logger.debug(
                        f"[DEPENDENCY] - Stored {entity_name} as-is; "
                        f"type={type(payload).__name__}"
                    )

                logger.info(f"[CONTEXT] - Stored computed parent {entity_name} (keys may vary by type)")

            except HTTPException:
                raise
            except Exception as dep_error:
                logger.error(f"[DEPENDENCY] - Unexpected error fetching {entity_name}: {dep_error}", exc_info=True)
                raise HTTPException(
                    status_code=502,
                    detail=f"Failed to fetch internal dependency: {entity_name}"
                )

        # ----------------------------------------------------------------
        # STEP 3: Compute inline ancestors
        # ----------------------------------------------------------------
        for inline_entity in _INLINE_COMPUTED_CHAIN:
            entity_name = inline_entity["name"]
            logger.debug(f"[INLINE] - Computing inline entity {entity_name}")
            
            shaped_data = {}
            evaluation_ctx = {"ctx": context}
            
            for attr_config in inline_entity.get("attrs", []):
                attr_name = attr_config["name"]
                attr_expr = attr_config["expr"]
                
                compiled_expr = compile_safe(attr_expr)
                shaped_data[attr_name] = eval(compiled_expr, safe_globals, evaluation_ctx)
            
            context[entity_name] = shaped_data
            logger.debug(f"[CONTEXT] - Stored inline entity {entity_name}")

            # --- Run validations for this inline entity ---
            if inline_entity.get("validations"):
                evaluation_ctx = {"ctx": context, **context}
                try:
                    for v in inline_entity["validations"]:
                        eval(compile_safe(v["pyexpr"]), safe_globals, evaluation_ctx)
                        logger.debug(f"[VALIDATION] - {entity_name} validation passed")
                except HTTPException as http_e:
                    logger.warning(f"[VALIDATION] - {entity_name} failed: {http_e.detail}")
                    raise
                except Exception as e:
                    logger.error(
                        f"[VALIDATION] - {entity_name} crashed during validation: {e}",
                        exc_info=True,
                    )
                    raise HTTPException(status_code=400, detail={"error": str(e)})

        # ----------------------------------------------------------------
        # STEP 4: Compute final entity attributes
        # ----------------------------------------------------------------
        logger.info(f"[COMPUTE] - Computing final entity {{ entity.name }}")
        logger.debug("[COMPUTE] - Raw context before computations:")
        try:
            preview = json.dumps(context, indent=2)[:800]
            logger.debug(preview + ("..." if len(preview) == 800 else ""))
        except Exception as e:
            logger.debug(f"[COMPUTE] - Could not serialize context: {e}")
        
        final_attributes: Dict[str, Any] = {}
        
        # Build evaluation context with all dependencies
        evaluation_ctx = {"ctx": context}
        
        # Also expose external sources directly by their alias
        for source_config in _EXTERNAL_REST_SOURCES:
            source_alias = source_config["alias"]
            entity_name = source_config["entity"]
            evaluation_ctx[source_alias] = context.get(entity_name, {})
        
        # --- Entity-level validation ---
        {% if validations %}
        evaluation_ctx = {"ctx": context}
        for k, v in context.items():
            evaluation_ctx[k] = v
        try:
            {% for v in validations %}
            eval(compile_safe({{ v.pyexpr | tojson }}), safe_globals, evaluation_ctx)
            {% endfor %}
        except HTTPException:
            raise
        except Exception as e:
            logger.error(f"[VALIDATION] - {{ entity.name }} validation failed: {e}", exc_info=True)
            raise HTTPException(status_code=400, detail={"error": str(e)})
        {% endif %}

        # Evaluate each attribute
        for attr_name, compiled_expr in _ENTITY_ATTRIBUTES.items():
            try:
                result = eval(compiled_expr, safe_globals, evaluation_ctx)
                final_attributes[attr_name] = result
                logger.debug(f"[COMPUTE] - {{ entity.name }}.{attr_name}: {type(result).__name__}")
            except HTTPException:
                raise 
            except Exception as compute_error:
                logger.error(f"[COMPUTE] - Error computing attribute {attr_name}: {compute_error}", exc_info=True)
                raise HTTPException(
                    status_code=500,
                    detail=f"Failed to compute attribute: {attr_name}"
                )

        # ----------------------------------------------------------------
        # STEP 5: Return result
        # ----------------------------------------------------------------
        logger.info(f"[SUCCESS] - Query {{ entity.name }} completed successfully")
        logger.debug(f"[RESULT] - Attributes: {list(final_attributes.keys())}")
        logger.debug("[COMPUTE] - Computed entity output:")
        try:
            preview = json.dumps(final_attributes, indent=2)[:800]
            logger.debug(preview + ("..." if len(preview) == 800 else ""))
        except Exception as e:
            logger.debug(f"[COMPUTE] - Could not serialize final result: {e}")
        
        return final_attributes

    except HTTPException:
        raise
    except Exception as unexpected_error:
        logger.exception(f"[ERROR] - Unexpected error in query {{ entity.name }}")
        raise HTTPException(status_code=500, detail="Internal server error")
